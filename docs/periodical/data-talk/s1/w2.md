# 第一季第二期（S1W2）

## 问答模块
--------------------------------
1. 提问环节
    1. [[issues #20](https://github.com/dantezhao/data-group/issues/20)]:app与web在基础数据的要求有所不同，如果app和web共同为同一业务服务，这两者之间的数据如何进行汇总处理？
    2. [[issues #22](https://github.com/dantezhao/data-group/issues/22)]:如何做好埋点工作和研发的协调和落地？怎么进行埋点工作的验证和效果评估？
2. 回答环节 
    1. [[issues #17](https://github.com/dantezhao/data-group/issues/17)] 通过订单表计算新客和用户下单留存应该怎么设计模型
        1. 这种需求的话，我能考虑的是设计两张表：
            1. 中间数据表，表结构：user_id, buy_num, dt 。这份表从流水表中清洗出用户和日期，一个用户不管一天买多东西，每天只有一条记录。
            2. 用户购买行为特征表，表结构：user_id, first_buy_date, last_buy_date，is_continuous_buy_rcnt_7_day,is_continuous_buy_rcnt_30_day。
        2. 解释一下
            1. 第二张表，来满足日常需求，里面有每个用户的第一次购买东西的日期，最后一次购买的日期，最近7天、30天是否连续购买商品，这些都是相对来讲比较固定的特征
            2. 然后解释第一张表，第一张是一个中间表，它有两个作用，第一个作用是来计算第二张表，提高计算效率，另一个是满足一些特定的需求，比如需求方想知道指定日期是否连续购买商品了，就可以从第一张表来计算，当然会有一点计算成本，但是我们已经初步汇总了一次，计算性能能提高一大部分。
    2. [[issues #21](https://github.com/dantezhao/data-group/issues/21)] 如何进行数据埋点方案及规范的定义，以及后续怎么进行维护和管理？
        1. 埋点数据内容包含：事件+属性+属性值
        2. 规范一定要做好，不然后期肯定维护不起，数据几乎白费。规范怎么定义看设计者的理解程度了，坑很多。后期维度对哪家公司来说都是头疼的事情，依赖于前面的规范。
    3. [[issues #24](https://github.com/dantezhao/data-group/issues/24)] 逻辑回归的连续型变量分箱处理，这一块除了基于业务经验，一般还有什么办法？大家平常做分箱处理在业务理解后，分箱用等频/等值的选择，以及分箱之后的Bing处理会怎么操作？
        1. 对于连续型变量分箱，如果是金融方面，建议用Weight Of Evidence
        2. 如果是离线的话，可以用单变量阈值选择，相当于单变量进行聚类，或者用Conditional Inference Tree递归也可以。单变量递归主要解决连续变量离散化的问题

## 主题讨论
--------------------------------
1. 机器学习的算法和模型讨论
    1. 机器学习什么情况使用什么算法模型
    2. 机器学习中数据处理的奇特办法
    3. [讨论地址](https://github.com/dantezhao/data-group/issues/19)